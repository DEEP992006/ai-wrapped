/**
 * ğŸ’¬ Basic Chat Example
 * Simple one-shot conversation with Ollama using LangChain
 */

import { ChatOllama } from "@langchain/ollama";
import { configDotenv } from "dotenv";

// ğŸ” Load environment variables
configDotenv();

// ğŸ¤– Initialize Ollama client
const ollama = new ChatOllama({
  baseUrl: "https://ollama.com",
  headers: {
    Authorization: "Bearer " + process.env.OLLAMA_API_KEY,
  },
  model: "kimi-k2:1t",
});

// ğŸ“¨ Define the message payload
const messages = [
  { role: "user", content: "hey" }
];

// ğŸš€ Send message and get response
const response = await ollama.invoke(messages);

// ğŸ“¤ Output the response
console.log(response.content);
