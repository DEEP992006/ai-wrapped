/**
 * ðŸ’¬ Memory-Enhanced Chat Example
 * Interactive chat with persistent memory using Mem0 and Ollama LLM
 * Remembers user preferences and context across conversations
 */

import { addMemory, searchMemory } from './index.js';
import { ollama } from '../app.js';
import * as readline from 'readline';

// ðŸ‘¤ Generate unique user ID for this session
const userId = "user-" + Date.now();

// ðŸ–¥ï¸ Setup readline interface for terminal input
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
});

// â“ Helper function to prompt user for input
function prompt(question) {
  return new Promise((resolve) => {
    rl.question(question, resolve);
  });
}

// ðŸš€ Start chat session
console.log("ðŸ¤– Chat with AI (with memory). Type 'exit' to quit.\n");

// ðŸ“ Initialize chat history array
const chatHistory = [];

// â™¾ï¸ Infinite chat loop
while (true) {
  // ðŸ“¥ Get user input
  const userInput = await prompt("You: ");
  
  // ðŸšª Check for exit command
  if (userInput.toLowerCase() === 'exit') {
    console.log("ðŸ‘‹ Goodbye!");
    rl.close();
    break;
  }

  // ðŸ” Search for relevant memories based on user input
  const memories = await searchMemory(userInput, userId);
  
  // ðŸ§  Build context from retrieved memories
  let memoryContext = "";
  if (memories && memories.length > 0) {
    memoryContext = "\n[Relevant memories: " + memories.map(m => m.memory).join("; ") + "]\n";
  }

  // âž• Add user message to chat history
  chatHistory.push({ role: "user", content: userInput });

  // ðŸ“¨ Create messages array with memory context for LLM
  const messagesWithContext = [
    { role: "system", content: `You are a helpful assistant. Remember previous context.${memoryContext}` },
    ...chatHistory
  ];

  // ðŸš€ Send to LLM and get response
  const response = await ollama.invoke(messagesWithContext);
  const assistantMessage = response.content;

  // ðŸ“¤ Output the response
  console.log(`\nðŸ¤– Assistant: ${assistantMessage}\n`);

  // âž• Add assistant response to chat history
  chatHistory.push({ role: "assistant", content: assistantMessage });

  // ðŸ’¾ Save conversation turn to persistent memory
  await addMemory([
    { role: "user", content: userInput },
    { role: "assistant", content: assistantMessage }
  ], userId);
}
